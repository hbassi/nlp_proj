{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import transformers\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = pd.read_json('yelp_review_training_dataset.jsonl',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                                               text  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q  Total bill for this horrible service? Over $8G...   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug  I have to say that this office really has it t...   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig  Went in for a lunch. Steak sandwich was delici...   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw  Today was my second out of three sessions I ha...   \n",
       "\n",
       "   stars  \n",
       "0      1  \n",
       "1      5  \n",
       "2      5  \n",
       "3      5  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533581 entries, 0 to 533580\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   review_id  533581 non-null  object\n",
      " 1   text       533581 non-null  object\n",
      " 2   stars      533581 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "rev.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_ratings = rev['stars']\n",
    "plt.title('Countplot of Ratings')\n",
    "sns.countplot(x=all_ratings);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data is not evenly split, with more polarizing reviews being the most popular. Postively rated restaurants are rated the highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We must now clean our review data to perform analysis on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_data):\n",
    "    text_data = text_data.lower()\n",
    "    #text_data = re.sub('\\w*\\d\\w*', \"\", text_data)\n",
    "    return text_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev['clean_text'] = rev.text.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1</td>\n",
       "      <td>total bill for this horrible service? over $8g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5</td>\n",
       "      <td>i *adore* travis at the hard rock's new kelly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5</td>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yi0R0Ugj_xUx_Nek0-_Qig</td>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5</td>\n",
       "      <td>went in for a lunch. steak sandwich was delici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11a8sVPMUFtaC7_ABRkmtw</td>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                                               text  \\\n",
       "0  Q1sbwvVQXV2734tPgoKj4Q  Total bill for this horrible service? Over $8G...   \n",
       "1  GJXCdrto3ASJOqKeVWPi6Q  I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "2  2TzJjDVDEuAW6MR5Vuc1ug  I have to say that this office really has it t...   \n",
       "3  yi0R0Ugj_xUx_Nek0-_Qig  Went in for a lunch. Steak sandwich was delici...   \n",
       "4  11a8sVPMUFtaC7_ABRkmtw  Today was my second out of three sessions I ha...   \n",
       "\n",
       "   stars                                         clean_text  \n",
       "0      1  total bill for this horrible service? over $8g...  \n",
       "1      5  i *adore* travis at the hard rock's new kelly ...  \n",
       "2      5  i have to say that this office really has it t...  \n",
       "3      5  went in for a lunch. steak sandwich was delici...  \n",
       "4      1  today was my second out of three sessions i ha...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model (simple LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rev['clean_text']\n",
    "y = rev['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state=123)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(max_df = 100, use_idf=True)\n",
    "tfid.fit_transform(X_train)\n",
    "X_train_vec = tfid.transform(X_train)\n",
    "X_test_vec = tfid.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480222, 171064)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=10000, solver='liblinear')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, C=1, solver='liblinear')\n",
    "lr.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8512\n"
     ]
    }
   ],
   "source": [
    "prediction = lr.predict(X_test_vec)\n",
    "#amount of non 5 predictions\n",
    "print(len(np.where(np.array(prediction) != 5)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.5442568264022939\n",
      "Precision is:  0.8348400706292689\n",
      "Recall is:  0.5442568264022939\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is: ', accuracy_score(prediction, y_test))\n",
    "print('Precision is: ', precision_score(prediction, y_test, average='weighted'))\n",
    "print('Recall is: ', recall_score(prediction, y_test, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ['THIS PLACE SERVES THE MOST SHIT FOOD OF ALL TIME AND MAKES ME WANT TO KILL MYSELF I LITERALLY HATE EVERYONE HERE AND ITS SO BAD AND DIRTY AND DISGUSTING HORRIBLE BAD SHIT BAD BAD BAD']\n",
    "example_vec = tfid.transform(example)\n",
    "prediction_e = lr.predict(example_vec)\n",
    "prediction_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now begin the use of the BERT model. First we will consider it on the filtered text, so uncased data. Then we will consider it on cased data. Potentially we can combine these 2 and average their predictions as our novel contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel, MultiLabelClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MultiLabelClassificationModel('bert', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total bill for this horrible service? over $. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i *adore* travis at the hard rock's new kelly ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have to say that this office really has it t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>went in for a lunch. steak sandwich was delici...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>today was my second out of three sessions i ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  stars\n",
       "0  total bill for this horrible service? over $. ...      1\n",
       "1  i *adore* travis at the hard rock's new kelly ...      5\n",
       "2  i have to say that this office really has it t...      5\n",
       "3  went in for a lunch. steak sandwich was delici...      5\n",
       "4  today was my second out of three sessions i ha...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bert = rev.drop(columns={'review_id', 'text'})\n",
    "#display(X_train_bert)\n",
    "display(type(X_train_bert.iloc[0]['stars']))\n",
    "X_train_bert = X_train_bert[['clean_text', 'stars']]\n",
    "X_train_bert.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, labels):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        review = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        return self.tokenizer.encode_plus(review, max_length=self.max_len, padding='max_length', return_attention_mask=True, return_tensors='pt', truncation=True), review, torch.tensor([label-1]).to(torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        review_length = len(self.data)\n",
    "        return review_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_training_data = ProcessData(X_train.to_numpy().tolist(), tokenizer, 100, y_train.to_numpy())\n",
    "tokenized_validation_data = ProcessData(X_val.to_numpy().tolist(), tokenizer, 100, y_val.to_numpy())\n",
    "tokenized_test_data = ProcessData(X_test.to_numpy().tolist(), tokenizer, 100, y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[  101,  1045,  2001,  2559,  2005,  1037,  2047, 13362, 22231,  2361,\n",
       "           1998,  1045,  1005,  2310,  2179,  2009,  1012,  1045,  2288,  1037,\n",
       "           2307,  2606, 12690,  1998,  2307,  2326,  2182,  1010,  1045,  3811,\n",
       "          16755,  2023,  2173,  1012,  1045,  1005,  2222,  2022,  2067,   102,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]])},\n",
       " \"i was looking for a new barbershop and i've found it. i got a great haircut and great service here, i highly recommend this place. i'll be back\",\n",
       " tensor([4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_training_data[0][0], tokenized_training_data[0][1], tokenized_training_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataloader\n",
    "params = {'batch_size': 32,\n",
    "          'num_workers': 0}\n",
    "loader_tokenized_training_data = torch.utils.data.DataLoader(tokenized_training_data, **params)\n",
    "loader_tokenized_validation_data = torch.utils.data.DataLoader(tokenized_validation_data, **params)\n",
    "loader_tokenized_test_data = torch.utils.data.DataLoader(tokenized_test_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = transformers.BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('total bill for this horrible service? over $8gs. these crooks actually had the nerve to charge us $69 for 3 pills. i checked online the pills can be had for 19 cents each! avoid hospital ers at all costs.',\n",
       " 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = tokenizer.encode_plus(X_train[0], max_length=100, padding='max_length', return_attention_mask=True, return_tensors='pt', truncation=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2561,  3021,  2005,  2023,  9202,  2326,  1029,  2058,  1002,\n",
       "          1022,  5620,  1012,  2122, 19302,  2015,  2941,  2018,  1996,  9113,\n",
       "          2000,  3715,  2149,  1002,  6353,  2005,  1017, 15345,  1012,  1045,\n",
       "          7039,  3784,  1996, 15345,  2064,  2022,  2018,  2005,  2539, 16653,\n",
       "          2169,   999,  4468,  2902,  9413,  2015,  2012,  2035,  5366,  1012,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/transformers/main_classes/output.html\n",
    "output = bert(**ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape, output[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTNet(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(BERTNet, self).__init__()\n",
    "        self.bert_model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop = nn.Dropout(p=0.1)\n",
    "        self.linear = nn.Linear(768, classes)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #print(input_ids,attention_mask )\n",
    "        output = self.bert_model(input_ids, attention_mask)\n",
    "        output = output[1]\n",
    "        output = self.drop(output)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTNet(5).to(device)\n",
    "#model = model.to(device)\n",
    "#ex = ex.to(device)\n",
    "ex['input_ids'] = ex['input_ids'].to(device)\n",
    "ex['attention_mask'] = ex['attention_mask'].to(device)\n",
    "ex['token_type_ids'] = ex['token_type_ids'].to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2769,  0.4492,  0.2295, -0.3332, -0.1133]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ex['input_ids'], ex['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2561,  3021,  2005,  2023,  9202,  2326,  1029,  2058,  1002,\n",
       "          1022,  5620,  1012,  2122, 19302,  2015,  2941,  2018,  1996,  9113,\n",
       "          2000,  3715,  2149,  1002,  6353,  2005,  1017, 15345,  1012,  1045,\n",
       "          7039,  3784,  1996, 15345,  2064,  2022,  2018,  2005,  2539, 16653,\n",
       "          2169,   999,  4468,  2902,  9413,  2015,  2012,  2035,  5366,  1012,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2977, 0.1948, 0.2122, 0.1442, 0.1510]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(ex['input_ids'], ex['attention_mask']), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n",
      "  0%|                                                                                        | 0/15007 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                              | 1/15007 [00:00<1:37:05,  2.58it/s]\u001b[A\n",
      "  0%|                                                                              | 2/15007 [00:00<1:32:06,  2.72it/s]\u001b[A\n",
      "  0%|                                                                              | 3/15007 [00:01<1:29:32,  2.79it/s]\u001b[A\n",
      "  0%|                                                                              | 4/15007 [00:01<1:27:26,  2.86it/s]\u001b[A\n",
      "  0%|                                                                              | 5/15007 [00:01<1:25:40,  2.92it/s]\u001b[A\n",
      "  0%|                                                                              | 6/15007 [00:02<1:24:05,  2.97it/s]\u001b[A\n",
      "  0%|                                                                              | 7/15007 [00:02<1:22:27,  3.03it/s]\u001b[A\n",
      "  0%|                                                                              | 8/15007 [00:02<1:23:00,  3.01it/s]\u001b[A\n",
      "  0%|                                                                              | 9/15007 [00:02<1:21:55,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 10/15007 [00:03<1:22:25,  3.03it/s]\u001b[A\n",
      "  0%|                                                                             | 11/15007 [00:03<1:22:01,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 12/15007 [00:03<1:21:52,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 13/15007 [00:04<1:22:08,  3.04it/s]\u001b[A\n",
      "  0%|                                                                             | 14/15007 [00:04<1:21:32,  3.06it/s]\u001b[A\n",
      "  0%|                                                                             | 15/15007 [00:04<1:21:11,  3.08it/s]\u001b[A\n",
      "  0%|                                                                             | 16/15007 [00:05<1:21:55,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 17/15007 [00:05<1:21:51,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 18/15007 [00:05<1:23:17,  3.00it/s]\u001b[A\n",
      "  0%|                                                                             | 19/15007 [00:06<1:22:55,  3.01it/s]\u001b[A\n",
      "  0%|                                                                             | 20/15007 [00:06<1:22:48,  3.02it/s]\u001b[A\n",
      "  0%|                                                                             | 21/15007 [00:06<1:22:27,  3.03it/s]\u001b[A\n",
      "  0%|                                                                             | 22/15007 [00:07<1:22:10,  3.04it/s]\u001b[A\n",
      "  0%|                                                                             | 23/15007 [00:07<1:21:49,  3.05it/s]\u001b[A\n",
      "  0%|                                                                             | 24/15007 [00:07<1:22:20,  3.03it/s]\u001b[A\n",
      "  0%|▏                                                                            | 25/15007 [00:08<1:21:12,  3.07it/s]\u001b[A\n",
      "  0%|▏                                                                            | 26/15007 [00:08<1:22:03,  3.04it/s]\u001b[A\n",
      "  0%|▏                                                                            | 27/15007 [00:08<1:21:42,  3.06it/s]\u001b[A\n",
      "  0%|▏                                                                            | 28/15007 [00:09<1:22:24,  3.03it/s]\u001b[A\n",
      "  0%|▏                                                                            | 29/15007 [00:09<1:22:41,  3.02it/s]\u001b[A\n",
      "  0%|▏                                                                            | 30/15007 [00:09<1:23:18,  3.00it/s]\u001b[A\n",
      "  0%|▏                                                                            | 31/15007 [00:10<1:23:19,  3.00it/s]\u001b[A\n",
      "  0%|▏                                                                            | 32/15007 [00:10<1:22:47,  3.01it/s]\u001b[A\n",
      "  0%|▏                                                                            | 33/15007 [00:10<1:23:18,  3.00it/s]\u001b[A\n",
      "  0%|▏                                                                            | 34/15007 [00:11<1:22:35,  3.02it/s]\u001b[A\n",
      "  0%|▏                                                                            | 35/15007 [00:11<1:21:46,  3.05it/s]\u001b[A\n",
      "  0%|▏                                                                            | 36/15007 [00:11<1:21:26,  3.06it/s]\u001b[A\n",
      "  0%|▏                                                                            | 37/15007 [00:12<1:22:41,  3.02it/s]\u001b[A\n",
      "  0%|▏                                                                            | 38/15007 [00:12<1:23:18,  2.99it/s]\u001b[A\n",
      "  0%|▏                                                                            | 39/15007 [00:12<1:22:48,  3.01it/s]\u001b[A\n",
      "  0%|▏                                                                            | 40/15007 [00:13<1:23:11,  3.00it/s]\u001b[A\n",
      "  0%|▏                                                                            | 41/15007 [00:13<1:23:16,  3.00it/s]\u001b[A\n",
      "  0%|▏                                                                            | 42/15007 [00:13<1:22:54,  3.01it/s]\u001b[A\n",
      "  0%|▏                                                                            | 43/15007 [00:14<1:22:12,  3.03it/s]\u001b[A\n",
      "  0%|▏                                                                            | 44/15007 [00:14<1:21:10,  3.07it/s]\u001b[A\n",
      "  0%|▏                                                                            | 45/15007 [00:14<1:21:33,  3.06it/s]\u001b[A\n",
      "  0%|▏                                                                            | 46/15007 [00:15<1:21:38,  3.05it/s]\u001b[A\n",
      "  0%|▏                                                                            | 47/15007 [00:15<1:21:36,  3.06it/s]\u001b[A\n",
      "  0%|▏                                                                            | 48/15007 [00:15<1:21:35,  3.06it/s]\u001b[A\n",
      "  0%|▎                                                                            | 49/15007 [00:16<1:21:07,  3.07it/s]\u001b[A\n",
      "  0%|▎                                                                            | 50/15007 [00:16<1:20:25,  3.10it/s]\u001b[A\n",
      "  0%|▎                                                                            | 51/15007 [00:16<1:21:03,  3.08it/s]\u001b[A\n",
      "  0%|▎                                                                            | 52/15007 [00:17<1:21:37,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 53/15007 [00:17<1:21:36,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 54/15007 [00:17<1:22:10,  3.03it/s]\u001b[A\n",
      "  0%|▎                                                                            | 55/15007 [00:18<1:21:43,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 56/15007 [00:18<1:22:13,  3.03it/s]\u001b[A\n",
      "  0%|▎                                                                            | 57/15007 [00:18<1:21:11,  3.07it/s]\u001b[A\n",
      "  0%|▎                                                                            | 58/15007 [00:19<1:21:11,  3.07it/s]\u001b[A\n",
      "  0%|▎                                                                            | 59/15007 [00:19<1:21:37,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 60/15007 [00:19<1:21:45,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 61/15007 [00:20<1:21:40,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 62/15007 [00:20<1:21:46,  3.05it/s]\u001b[A\n",
      "  0%|▎                                                                            | 63/15007 [00:20<1:21:53,  3.04it/s]\u001b[A\n",
      "  0%|▎                                                                            | 64/15007 [00:21<1:23:41,  2.98it/s]\u001b[A\n",
      "  0%|▎                                                                            | 65/15007 [00:21<1:22:56,  3.00it/s]\u001b[A\n",
      "  0%|▎                                                                            | 66/15007 [00:21<1:21:58,  3.04it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                            | 67/15007 [00:22<1:22:22,  3.02it/s]\u001b[A\n",
      "  0%|▎                                                                            | 68/15007 [00:22<1:21:49,  3.04it/s]\u001b[A\n",
      "  0%|▎                                                                            | 69/15007 [00:22<1:21:13,  3.07it/s]\u001b[A\n",
      "  0%|▎                                                                            | 70/15007 [00:23<1:20:56,  3.08it/s]\u001b[A\n",
      "  0%|▎                                                                            | 71/15007 [00:23<1:21:27,  3.06it/s]\u001b[A\n",
      "  0%|▎                                                                            | 72/15007 [00:23<1:22:15,  3.03it/s]\u001b[A\n",
      "  0%|▎                                                                            | 73/15007 [00:24<1:22:00,  3.03it/s]\u001b[A\n",
      "  0%|▍                                                                            | 74/15007 [00:24<1:22:03,  3.03it/s]\u001b[A\n",
      "  0%|▍                                                                            | 75/15007 [00:24<1:21:42,  3.05it/s]\u001b[A\n",
      "  1%|▍                                                                            | 76/15007 [00:25<1:21:49,  3.04it/s]\u001b[A\n",
      "  1%|▍                                                                            | 77/15007 [00:25<1:21:22,  3.06it/s]\u001b[A\n",
      "  1%|▍                                                                            | 78/15007 [00:25<1:21:17,  3.06it/s]\u001b[A\n",
      "  1%|▍                                                                            | 79/15007 [00:26<1:21:22,  3.06it/s]\u001b[A\n",
      "  1%|▍                                                                            | 80/15007 [00:26<1:21:46,  3.04it/s]\u001b[A\n",
      "  1%|▍                                                                            | 81/15007 [00:26<1:21:10,  3.06it/s]\u001b[A\n",
      "  1%|▍                                                                            | 82/15007 [00:26<1:20:56,  3.07it/s]\u001b[A\n",
      "  1%|▍                                                                            | 83/15007 [00:27<1:21:26,  3.05it/s]\u001b[A\n",
      "  1%|▍                                                                            | 84/15007 [00:27<1:21:55,  3.04it/s]\u001b[A\n",
      "  1%|▍                                                                            | 85/15007 [00:28<1:22:40,  3.01it/s]\u001b[A\n",
      "  1%|▍                                                                            | 86/15007 [00:28<1:22:37,  3.01it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for epoch in trange(1):\n",
    "    print('Epoch: ' , str(epoch))\n",
    "    print('==================================')\n",
    "    model = model.train()\n",
    "    #print('Done training')\n",
    "    correct = 0\n",
    "    losses = []\n",
    "    for data in tqdm(loader_tokenized_training_data):\n",
    "        #print(data[2].squeeze(0).shape)\n",
    "        \n",
    "        batch_ids = data[0]['input_ids']\n",
    "        batch_ids = batch_ids.flatten().reshape((batch_ids.shape[0], batch_ids.shape[2]))\n",
    "        batch_masks = data[0]['attention_mask']\n",
    "        batch_masks = batch_masks.flatten().reshape((batch_masks.shape[0], batch_masks.shape[2]))\n",
    "        #print(batch_ids)\n",
    "        #print(batch.flatten().reshape((batch.shape[0], batch.shape[2])).shape)\n",
    "       \n",
    "        output = model(batch_ids.to(device), batch_masks.to(device))\n",
    "        #print(data)\n",
    "        #print(output)\n",
    "        _, prediction = torch.max(output, dim=1)\n",
    "        #print(prediction)\n",
    "        #print(output)\n",
    "        #print(data[2])\n",
    "        loss = criterion(output, torch.max(data[2].to(device), 1)[1])\n",
    "        correct += torch.sum(prediction.to(device) == data[2].to(device))\n",
    "        #print(correct)\n",
    "        #print('Loss: ', loss.item())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    #for vdata in loader_tokenized_validation_data:\n",
    "        \n",
    "        \n",
    "final_acc, final_loss = correct / len(tokenized_training_data), np.mean(losses)\n",
    "final_acc, final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_training_data[0][0]['input_ids'].flatten()\n",
    "(tokenized_training_data[1][0]['input_ids'].flatten()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
